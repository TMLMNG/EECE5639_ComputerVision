{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p1",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zRN4NA7SqTMaG-64AEuHtB9tmhDTswtJ",
      "authorship_tag": "ABX9TyPLDjnx2KktP1WonYFJErOc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scheung97/EECE5639_ComputerVision/blob/main/p1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBN8SNrx7x0y"
      },
      "source": [
        "# Northeastern University\n",
        "# EECE5639 Computer Vision\n",
        "\n",
        "# Spenser Cheung & Tim Liming\n",
        "\n",
        "# Project 1\n",
        "\n",
        "import cv2 \n",
        "import numpy as np \n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiyTMG2BRlfi"
      },
      "source": [
        "!python3 --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAj3WRw2KJn9",
        "outputId": "2134453e-b74f-46e2-e668-69880f1ce2f6"
      },
      "source": [
        "# Mount Google Drive in Google Colab\n",
        "\n",
        "# Public 'Office' folder link: \n",
        "# https://drive.google.com/drive/folders/1foo2U9aRLJ5osnCSF4ykIGJrTlZ7ubOk?usp=sharing\n",
        "\n",
        "# Public 'RedChair' folder link: \n",
        "# https://drive.google.com/drive/folders/1gH_nkSJy04r9ankfNtUAYSOMpVML53bx?usp=sharing\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "Office_path = \"/content/gdrive/MyDrive/EECE5639_P1_Office\"\n",
        "RedChair_path = \"/content/gdrive/MyDrive/EECE5639_P1_RedChair\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e71zLXjZ9l4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de19863d-6c42-4bd1-c0ab-ccc6cc8a1bcd"
      },
      "source": [
        "# i. Read in a sequence of image frames and make them grayscale.\n",
        "\n",
        "# Office\n",
        "office_files = [filename for filename in sorted(os.listdir(Office_path)) if os.path.isfile(os.path.join(Office_path, filename))]\n",
        "\n",
        "office_images = []    \n",
        "for i in range(0, len(office_files)): \n",
        "    img = cv2.imread(os.path.join(Office_path, office_files[i]))\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n",
        "    office_images.append(gray_img)\n",
        "\n",
        "office_images = np.array(office_images)\n",
        "print(office_images.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(460, 240, 320)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzWMkJ1GUNza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d1893c-d568-4288-c4d7-d43ca387b7db"
      },
      "source": [
        "# i. Read in a sequence of image frames and make them grayscale.\n",
        "\n",
        "# RedChair\n",
        "redchair_files = [filename for filename in sorted(os.listdir(RedChair_path)) if os.path.isfile(os.path.join(RedChair_path, filename))]\n",
        "\n",
        "redchair_images = []\n",
        "for i in range(0, len(redchair_files)): \n",
        "    img = cv2.imread(os.path.join(RedChair_path, redchair_files[i]))\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n",
        "    redchair_images.append(gray_img)\n",
        "\n",
        "redchair_images = np.array(redchair_images)\n",
        "print(redchair_images.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(353, 240, 320)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G320sT6bEchO"
      },
      "source": [
        "# ii. As enough frames are available, apply a 1-D differential operator at each \n",
        "# pixel to compute a temporal derivative.\n",
        "\n",
        "#images = office_images\n",
        "images = redchair_images\n",
        "\n",
        "# simple filter\n",
        "temporal_filter = 0.5 * np.array([-1., 0., 1.])\n",
        "\n",
        "frame = 162\n",
        "cv2_imshow(images[frame,:,:])\n",
        "print('--------------------------------')\n",
        "\n",
        "frames1 = [images[frame-1,:,:], images[frame,:,:], images[frame+1,:,:]]\n",
        "img1 = np.tensordot(frames1, temporal_filter, axes=(0,0)) # tensor product\n",
        "plt.imshow(img1, cmap='gray')\n",
        "plt.show()\n",
        "print('--------------------------------')\n",
        "\n",
        "\n",
        "# 1D derivative of a Gaussian\n",
        "tsigma = 2.0\n",
        "\n",
        "gaussian_filter = 1/16 * np.array([1, 4, 6, 4, 1])\n",
        "\n",
        "frame = 162\n",
        "frames2 = [images[frame-2,:,:], images[frame-1,:,:], \\\n",
        "           images[frame,:,:], \\\n",
        "           images[frame+1,:,:], images[frame+2,:,:]]\n",
        "img2 = np.tensordot(frames2, gaussian_filter, axes=(0,0)) # tensor product\n",
        "\n",
        "plt.imshow(img2, cmap='gray')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HP3XlCVKVLq"
      },
      "source": [
        "# main\n",
        "\n",
        "# ii. As enough frames are available, apply a 1-D differential operator at each \n",
        "# pixel to compute a temporal derivative.\n",
        "\n",
        "#images = office_images\n",
        "images = redchair_images\n",
        "\n",
        "#play_frames(images)\n",
        "print(images.shape)\n",
        "\n",
        "# compute temporal derivative\n",
        "operator_1d = np.array([-1, 0, 1])\n",
        "kernel2 = np.vstack((np.vstack(([0,0,0], operator_1d)), [0,0,0]))\n",
        "print(kernel2)\n",
        "\n",
        "td = []\n",
        "for i in range(1, len(images)):\n",
        "    diff = cv2.absdiff(images[i], images[i-1])\n",
        "    td.append(diff)\n",
        "\n",
        "    #frames1 = [images[i-1], images[i], images[i]]\n",
        "    #img1 = np.tensordot(frames1, operator_1d, axes=(0,0)) # tensor product\n",
        "    #img2 = cv2.filter2D(src=images[i], ddepth=-1, kernel=kernel2)\n",
        "    #cv2_imshow(diff)\n",
        "    #cv2_imshow(img1)\n",
        "    #cv2_imshow(img2)\n",
        "    #td.append(img2)\n",
        "    #break\n",
        "td = np.array(td)\n",
        "\n",
        "#play_frames(td)\n",
        "print(td.shape)\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# iii. Threshold the absolute values of the derivatives to create a 0 and 1 \n",
        "# mask of the moving objects.\n",
        "thresh = 25\n",
        "maxValue = 255\n",
        "\n",
        "mask = []\n",
        "for i in range(len(td)):\n",
        "    img = td[i]\n",
        "    src = img.astype(np.uint8)\n",
        "    th, dst = cv2.threshold(src, thresh, maxValue, cv2.THRESH_BINARY);\n",
        "    mask.append(dst)\n",
        "mask = np.array(mask)\n",
        "\n",
        "#play_frames(mask)\n",
        "print(mask.shape)\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# iv. Combine the mask with the original frame to display the results.\n",
        "\n",
        "output = []\n",
        "for i in range(1, len(images)):\n",
        "    img = np.multiply(images[i], mask[i-1])\n",
        "    output.append(img)\n",
        "output = np.array(output)\n",
        "\n",
        "play_frames(output)\n",
        "print(output.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}